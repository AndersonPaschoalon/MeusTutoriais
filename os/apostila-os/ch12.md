# **Capítulo 12 — Confiabilidade e Segurança**

Assim como Tanenbaum gosta de lembrar em seus textos, computadores embarcados — especialmente aqueles escondidos dentro de carros, marcapassos, máquinas industriais e controladores de satélites — não têm o luxo de “travar” discretamente atrás de uma tela azul. Um microcontrolador que para no momento errado não causa apenas irritação: pode causar falhas caras, perigosas e irreversíveis.
Por isso, a confiabilidade e a segurança não são meros complementos; são o cerne do design embarcado. Neste capítulo, estudaremos os mecanismos que mantêm o sistema no rumo, mesmo quando tudo ao redor parece conspirar contra ele.

---

## **12.1 Watchdog Timer: o cão de guarda do sistema**

Imagine um cachorro inquieto, cuja única função na vida é verificar se você ainda está se mexendo. Se você parar — talvez adormecido ou distraído — ele imediatamente começa a latir para acordá-lo. O *watchdog timer* (WDT) funciona exatamente assim: é um periférico que reinicia o sistema caso o software deixe de “alimentá-lo” periodicamente.

O objetivo é simples:
**Evitar que o MCU permaneça preso em estados inválidos, deadlocks, loops infinitos ou corrupção de memória silenciosa.**

Em muitos microcontroladores ARM Cortex-M, o watchdog é um módulo dedicado com um contador decrescente. A cada intervalo configurado, o software precisa escrever uma sequência específica num registrador — muitas vezes algo como `0xAAAA` seguido de `0x5555`. Caso contrário, o watchdog assume que o sistema travou e aciona o reset.

#### **Exemplo em C — Watchdog no STM32 (HAL)**

Trecho adaptado para fins educacionais:

```c
// Exemplo didático baseado em STM32 HAL
IWDG_HandleTypeDef hiwdg;

void watchdog_init(void) {
    hiwdg.Instance = IWDG;
    hiwdg.Init.Prescaler = IWDG_PRESCALER_64;
    hiwdg.Init.Reload = 1000;  // timeout ~1s dependendo do clock LSI
    HAL_IWDG_Init(&hiwdg);
}

void loop_principal(void) {
    while (1) {
        // Lógica principal
        processa_eventos();

        // Alimenta o watchdog
        HAL_IWDG_Refresh(&hiwdg);
    }
}
```

Em Linux embarcado, a mesma ideia aparece no driver `/dev/watchdog`, que reinicia o sistema se a aplicação não escrever no arquivo especial:

```c
// Linux: alimentando o watchdog via /dev/watchdog
int fd = open("/dev/watchdog", O_WRONLY);
while (1) {
    write(fd, "\0", 1);   // "pat" no watchdog
    sleep(1);
}
```

#### **Watchdog Windowed (Janela de Alimentação)**

Versões mais sofisticadas exigem que o “alimento” chegue **não cedo demais**, nem **tarde demais**.
Isso evita loops rápidos que inadvertidamente fiquem chamando `refresh()` continuadamente sem realizar trabalho útil.

---

## **12.2 Fail-safe e Fail-recovery**

Se o watchdog é o cachorro que impede um travamento prolongado, o *fail-safe* é a sensação pragmática de que, mesmo quando tudo dá errado, o dano deve ser limitado. Sistemas embarcados são projetados não apenas para funcionar quando tudo vai bem, mas principalmente para **falhar de forma previsível e controlada**.

#### **Fail-safe**

O ideal é que, ao detectar uma falha séria:

* atuadores vão para posições seguras;
* saídas críticas são desabilitadas;
* sensores param de produzir dados enganadores;
* o sistema entra num modo restrito.

Exemplo típico:
Um controlador de motor que perde leitura do encoder deve imediatamente reduzir a velocidade ou cortar potência, jamais continuar acelerando às cegas.

#### **Fail-recovery**

Uma vez contida a falha, tenta-se recuperar o funcionamento normal:

* reinicialização de subsistemas;
* repetição de leituras;
* troca de canal de comunicação;
* fallback para firmware redundante.

#### **Exemplo prático — fallback superficial de um driver**

```c
// Pseudocódigo baseado em lógica comum de drivers industriais
int leitura_encoder(void) {
    int valor = hw_leitura_encoder();
    if (valor < 0) {
        log("Falha no encoder, usando valor anterior.");
        return valor_cacheado;
    }
    valor_cacheado = valor;
    return valor;
}
```

Esse comportamento não é perfeito, mas evita oscilações violentas em atuadores.

#### **Fail-safe ao estilo de Tanenbaum**

Como ele diria:

> “Quando o sistema falha, o hardware geralmente não se importa. É o engenheiro que deve decidir se ‘falha’ significa desligar uma bomba, pousar um drone ou simplesmente imprimir uma mensagem obscura no console.”

---

## **12.3 Tolerância a falhas**

Fail-safe é sobre parar de machucar o mundo.
Tolerância a falhas é sobre **seguir funcionando**, mesmo sob ataques do destino.

Existem dois grandes pilares aqui:

#### **1. Redundância**

* **Temporal**: repetir operações e verificar consistência.
* **Espacial**: mais de um dispositivo executa a mesma tarefa.
* **Informacional**: dados codificados com redundância (ECC, CRC).

Sistemas automotivos ASIL-D frequentemente usam dois MCUs executando o mesmo código e comparando resultados (*lockstep*). Se divergem, o sistema assume falha.

#### **2. Degradação graciosa**

Parte do sistema falha, mas o restante continua funcionando de modo limitado.
Exemplo clássico:
Um drone perde a leitura de GPS → volta para modo de estabilização usando apenas IMU e barômetro.

#### **Exemplo — votação tripla (TMR)**

Um exemplo simplificado de *Triple Modular Redundancy*:

```c
// Exemplo didático de TMR (não otimizado, para fins de clareza)
int leitura_sensor_tmr(void) {
    int a = le_sensor_A();
    int b = le_sensor_B();
    int c = le_sensor_C();

    // Retorna o valor que mais aparece (votação)
    if (a == b || a == c) return a;
    if (b == c) return b;

    // Caso extremo: nenhum bate
    log("TMR: leituras inconsistentes!");
    return a; // fallback arbitrário
}
```

Na prática, versões industriais aplicam filtros, limiares e CRCs para evitar valores "corrompidos" passarem despercebidos.


## **12.4 CRC, Checagem de Integridade e ECC**

Um microcontrolador vive cercado de perigos invisíveis:
menos radiação cósmica do que computadores em órbita, certamente, mas ainda assim sujeito a ruídos, interferências eletromagnéticas, fontes de alimentação baratas e barramentos longos o suficiente para que qualquer distúrbio cause bits errados.

Para defender-se disso tudo, o firmware precisa de mecanismos de integridade — formas matemáticas de detectar (e às vezes corrigir) corrupção silenciosa.

### **12.4.1 CRC — o guardião aritmético dos bytes**

O *Cyclic Redundancy Check* (CRC) é um dos métodos mais usados para detectar corrupção de dados em transmissões e armazenamento.
Ele funciona como uma divisão polinomial sobre os bits da mensagem — uma ideia matemática muito mais elegante do que o termo “checksum” sugere.

Tanenbaum provavelmente diria:

> “Se o hardware é o reino da eletricidade, então o CRC é o imposto matemático que deve ser pago para atravessá-lo com segurança.”

#### **Como o CRC funciona (intuitivamente)**

1. Pegamos a sequência de bits.
2. Interpretamos como um número polinomial.
3. Dividimos esse número por um polinômio gerador fixo.
4. O resto da divisão é o CRC.

Se algum bit mudar, as chances de o resto permanecer igual são extremamente pequenas (para CRCs bem escolhidos).

#### **Exemplo de CRC32 em C (estilo Linux kernel)**

```c
// Tabela clássica dependente de polinômio CRC32-IEEE
// Trecho representativo simplificado
uint32_t crc32_tab[] = { /* ... tabela real teria 256 entradas ... */ };

uint32_t crc32(const void *data, size_t len) {
    const uint8_t *p = data;
    uint32_t crc = ~0U;

    while (len--) {
        crc = crc32_tab[(crc ^ *p++) & 0xFF] ^ (crc >> 8);
    }
    return ~crc;
}
```

Sistemas embarcados usam esse tipo de CRC em:

* frames de comunicação (UART, CAN, Ethernet, modbus);
* validação de firmware na flash;
* logs críticos;
* configuração persistente (EEPROM/flash interna).

---

### **12.4.2 Checksums simples**

Mais baratos que CRCs, mas menos robustos.
São usados quando a integridade “leve” já basta (ex.: tabelas internas do bootloader, pacotes pequenos).

Exemplo, soma modular de 8 bits:

```c
uint8_t checksum8(uint8_t *data, size_t len) {
    uint8_t c = 0;
    for (size_t i = 0; i < len; i++)
        c += data[i];
    return ~c; // complemento para facilitar verificação
}
```

---

### **12.4.3 ECC — detecção e correção de erros na memória**

Enquanto o CRC detecta corrupção, o **ECC (Error Correcting Code)** pode corrigir automaticamente certos padrões de erro.
O mais clássico é o código **Hamming SEC-DED** (Single Error Correction, Double Error Detection).

Um bit virou? O ECC corrige.
Dois bits viraram? O ECC detecta e alerta, evitando decisões baseadas em dados corrompidos.

Memórias ECC são comuns em:

* automotivo ASIL-C/D;
* aplicações médicas;
* servidores;
* controladores de voo;
* DSPs de telecom.

#### **Exemplo: leitura de flash com ECC ativado (pseudo-driver)**

```c
int flash_read(uint32_t addr, uint8_t *buf, size_t len) {
    for (size_t i = 0; i < len; i++) {
        uint8_t raw = flash_hw_read_byte(addr + i);
        uint8_t ecc  = flash_hw_read_ecc(addr + i);

        if (!ecc_verify(raw, ecc)) {
            if (ecc_correctable(raw, ecc)) {
                buf[i] = ecc_correct(raw, ecc);
            } else {
                log("Erro irrecuperável na flash!");
                return -EIO;
            }
        } else {
            buf[i] = raw;
        }
    }
    return 0;
}
```

---

## **12.5 Segurança de Firmware (Assinatura e Criptografia)**

Se antes nos preocupávamos com falhas acidentais, agora tratamos das falhas **intencionais**.
Um microcontrolador que controla algo minimamente importante — um medidor, um alarme, um módulo automotivo, uma fechadura eletrônica, uma ponteira industrial — é alvo de ataques reais.

A questão é simples:
**Como garantir que apenas firmware legítimo execute na plataforma?**

Aqui entram dois mecanismos fundamentais:

1. **Assinatura digital** para *autenticidade* e *integridade*
2. **Criptografia** para *confidencialidade*

---

### **12.5.1 Assinatura digital de firmware**

A ideia é elegante:
O fabricante assina o firmware com uma chave privada.
O bootloader embarcado possui a chave pública e verifica a assinatura antes de iniciar o código.

#### **Fluxo típico**

1. Gerar hash (SHA-256) da imagem binária.
2. Assinar o hash com a chave privada (RSA, ECDSA).
3. Embutir ou anexar assinatura ao firmware.
4. No boot:

   * Bootloader calcula novamente o hash.
   * Verifica assinatura usando chave pública embutida.
   * Executa somente se válida.

#### **Exemplo simplificado em C — verificação ECDSA (conceitual)**

*(Adaptado de fluxos reais típicos em bootloaders seguros)*

```c
#include "ecdsa.h"    // biblioteca hipotética
#include "sha256.h"

bool verifica_firmware(uint8_t *image, size_t len,
                       uint8_t *signature, size_t sig_len,
                       const uint8_t *public_key)
{
    uint8_t hash[32];
    sha256(image, len, hash);
    return ecdsa_verify(public_key, hash, signature, sig_len);
}
```

O bootloader deve ser minimalista, auditável e imutável — muitas vezes protegido por “read-out protection” ou área OTP.

---

### **12.5.2 Criptografia do firmware**

A assinatura garante autenticidade; a criptografia garante que ninguém copie seu firmware ou faça engenharia reversa trivial.

MCUs modernos frequentemente oferecem aceleração AES por hardware.

#### **Fluxo típico**

* firmware é criptografado no build com AES-128/256;
* bootloader contém chave em área protegida;
* durante o boot, o firmware é descriptografado para RAM ou executado on-the-fly.

#### **Exemplo didático usando AES (pseudocódigo)**

```c
void decifra_firmware(uint8_t *dst, const uint8_t *src, size_t len) {
    aes_ctx ctx;
    aes_init(&ctx, firmware_key);
    for (size_t i = 0; i < len; i += 16) {
        aes_decrypt_block(&ctx, src + i, dst + i);
    }
}
```

---

### **12.5.3 Anti-rollback: impedindo downgrade malicioso**

Se o atacante não pode instalar um firmware alterado, talvez tente instalar um *antigo*, mas vulnerável.
Daí a necessidade de metadados que mantenham o contador de versão monotonicamente crescente — muitas vezes armazenado em algum tipo de memória que só pode ser incrementada (OTP fuse, monotonic counter, trust zone secure storage).

---

### **12.5.4 Proteções físicas e lógicas adicionais**

* **Read-out protection** de flash interna.
* **Debug lock** (desabilitar SWD/JTAG em produção).
* **Secure boot** em camadas.
* **Regiões de memória executável/non-executable (XN bits)**.
* **MPU para impedir execução em RAM contaminada**.
* **TrustZone-M** para separar mundo seguro e não seguro.

Tanenbaum provavelmente encerraria com algo como:

> “Em sistemas embarcados, a segurança não é um recurso opcional; é uma característica emergente de todas as camadas — do silício ao compilador.”

